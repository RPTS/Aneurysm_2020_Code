{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import ttest_ind, normaltest\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE_cv(scaler, selector, dfX, dfy, method, fe_niter=30):\n",
    "    '''\n",
    "    scaler (e.g. StandardScaler) and selector (e.g. RFE) are scikit-learn objects\n",
    "    dfX: feature matrix\n",
    "    dfy: response vector\n",
    "    method: 1: LOO; 2: 80/20\n",
    "    fe_niter: number of feature elimination iterations\n",
    "    \n",
    "    returns frequency (max. is fe_niter) of each feature column in terms of \n",
    "    the number of times selcted by the selector, in descending order\n",
    "    '''\n",
    "    X = np.array(dfX)\n",
    "    ylab = np.array(dfy)\n",
    "    pipeline = Pipeline(steps=[('scaler', scaler),('selector', selector)])\n",
    "\n",
    "    selected = []\n",
    "    \n",
    "    if method==1:  # leave one out\n",
    "        N = X.shape[0]\n",
    "        acc = 0\n",
    "        for i in range(N):\n",
    "            mask = np.ones((N,), dtype=bool)\n",
    "            mask[i] = 0\n",
    "            # scaler based on N-1 cases\n",
    "            Xtrain = X[mask]\n",
    "            pipeline.fit(Xtrain, ylab[mask])\n",
    "            selected.append(np.nonzero(selector.get_support())[0])\n",
    "    else:  # randomly select 80% as training set\n",
    "        for k in range(fe_niter):\n",
    "            trainX, testX, trainy, testy = train_test_split(X, ylab, test_size=0.2, random_state=k)\n",
    "            pipeline.fit(trainX, trainy)\n",
    "            selected.append(np.nonzero(selector.get_support())[0])\n",
    "    freq = np.bincount(np.array(selected).flatten())\n",
    "    columns = list(dfX.columns[np.argsort(freq)[-7:]])\n",
    "    freq = list(np.sort(freq)[-7:])\n",
    "    freq.reverse()\n",
    "    columns.reverse()\n",
    "    return freq, columns\n",
    "\n",
    "\n",
    "def cv(Xs, models, scaler, ylab, test_indices, print_loo=False):\n",
    "    '''\n",
    "    Xs and models are lists.\n",
    "    Test using each list of features and each model\n",
    "    Scaling is applied before inputting into each model\n",
    "    \n",
    "    If test_indices is not [], then also test the specific test set\n",
    "    (using the other for training)\n",
    "    Otherwise, use the two default validation methods (LOO and 80/20)\n",
    "    \n",
    "    Set print_loo to true to print the result for every single case \n",
    "    in the LOO validation\n",
    "    '''\n",
    "    # number of validation methods\n",
    "    if test_indices != []:\n",
    "        n_methods = 3\n",
    "    else:\n",
    "        n_methods = 2\n",
    "        \n",
    "    results = np.zeros((len(models), n_methods*len(Xs)))\n",
    "    cv_niter=100  # repeat\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        pipeline = Pipeline(steps=[('scaler', scaler),('model', model)])\n",
    "        for j in range(len(Xs)):\n",
    "            X = Xs[j]\n",
    "            N = X.shape[0]\n",
    "            # leave-one-out\n",
    "            LOO_acc = np.zeros((N,))\n",
    "            for k in range(N):\n",
    "                mask = np.ones((N,), dtype=bool)\n",
    "                mask[k] = 0\n",
    "                # scaler based on N-1 cases\n",
    "                Xsub = X[mask]\n",
    "                # test case\n",
    "                Xtest = np.array(X.iloc[k,:]).reshape(1, -1)\n",
    "\n",
    "                pipeline.fit(Xsub, ylab[mask])\n",
    "                LOO_acc[k] = np.mean(pipeline.predict(Xtest) == ylab[k])\n",
    "            if print_loo: \n",
    "                print(np.nonzero(LOO_acc==0)[0])\n",
    "            results[i, j*n_methods] = np.mean(LOO_acc)\n",
    "            # 80-20 split\n",
    "            cv82_acc = np.zeros((cv_niter,))\n",
    "            for k in range(cv_niter):\n",
    "                trainX, testX, trainy, testy = train_test_split(X, ylab, test_size=0.2, random_state=k)\n",
    "                pipeline.fit(trainX, trainy)\n",
    "                pred = pipeline.predict(testX)\n",
    "                cv82_acc[k] = np.mean(pred == testy)\n",
    "            results[i, j*n_methods+1] = np.mean(cv82_acc)\n",
    "            \n",
    "            # train test\n",
    "            if test_indices!=[]:\n",
    "                trainX = X.drop(test_indices, axis=0)\n",
    "                trainy = ylab.drop(test_indices, axis=0)\n",
    "                testX = X.iloc[test_indices,:]\n",
    "                testy = ylab.iloc[test_indices]\n",
    "                pipeline = Pipeline(steps=[('scaler', scaler),('model', model)])\n",
    "                pipeline.fit(trainX, trainy)\n",
    "                correct = pipeline.predict(testX)==testy\n",
    "                results[i, j*n_methods+2] = np.mean(correct)\n",
    "    return results\n",
    "\n",
    "\n",
    "def remove_highcc(X, cc_cutoff):\n",
    "    '''\n",
    "    Remove highly correlated features as defined by Pearson correlation \n",
    "    exceeding the cc_cutoff threshold (in terms of magnitude)\n",
    "    '''\n",
    "    highc_row, highc_col = np.nonzero(np.abs(np.corrcoef(X.transpose()))>=cc_cutoff) \n",
    "    diff_var = highc_row != highc_col\n",
    "    highc_row, highc_col = highc_row[diff_var], highc_col[diff_var]  \n",
    "    highc_pair = []; highc_delete = []\n",
    "    for r,c in zip(highc_row, highc_col):\n",
    "        if (min(r,c), max(r,c)) not in highc_pair:\n",
    "            if r<=c:\n",
    "                highc_delete.append(c)\n",
    "            else:\n",
    "                highc_delete.append(r)\n",
    "            highc_pair.append((min(r,c), max(r,c)))\n",
    "    mask = np.ones((X.shape[1],), dtype=bool)\n",
    "    mask[highc_delete] = 0\n",
    "    return X.iloc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(\n",
    "           path='AllNewFeatures1.csv', \n",
    "           ttest_crit=0.1, \n",
    "           cc_cutoff=0.99, \n",
    "           fs_method=1,\n",
    "           fs_niter=30, n_var=7, \n",
    "           fs_models=[(SelectKBest(score_func=f_classif,k=5),2), \n",
    "                      (RFE(SVC(kernel='linear'), n_features_to_select=5),2), \n",
    "                      (RFE(LogisticRegression(solver='liblinear'), n_features_to_select=5),2),\n",
    "                      (RFE(RandomForestClassifier(n_estimators=20), n_features_to_select=5),2)],\n",
    "           fs_model_names=['SelectKBest', 'RFE(SVM)', 'RFE(LR)', 'RFE(RF)'],\n",
    "           scaler=StandardScaler(),\n",
    "           print_loo=False):\n",
    "    '''\n",
    "    path: data file name\n",
    "    ttest_crit: integer for top N variables; float for cutoff of p-value\n",
    "    fs_method: 1: 80/20 x 30 rep; 2: LOO; 3: 80% LOO\n",
    "    n_var: number of variables to show from automated fs\n",
    "    \n",
    "    the default values are the ones used in the final results\n",
    "    '''\n",
    "    # original data\n",
    "    allft = pd.read_csv(path)\n",
    "    ally = allft['Group']\n",
    "    allX = allft.iloc[:,2:]\n",
    "    allX = remove_highcc(allX, cc_cutoff)\n",
    "    # prepare train/test sets\n",
    "    if fs_method==3:\n",
    "        trainX, testX, trainy, testy = train_test_split(allX, ally, test_size=7/37, random_state=5)\n",
    "        print('cases excluded from feature selection:')\n",
    "        print(np.array(testy.index))\n",
    "        print(np.array(testy))\n",
    "    else:\n",
    "        eval_method = 1\n",
    "        trainX, trainy = allX.copy(), ally.copy()\n",
    "    \n",
    "    ### step 1: t-test on dpX --> take top (n_ttest) : \"ttestX\"\n",
    "    np.random.seed(12345678)\n",
    "    tstat, pval = ttest_ind(trainX[trainy==1],trainX[trainy==0], equal_var=False)\n",
    "    if ttest_crit < 1:\n",
    "        n_ttest = sum(pval<=ttest_crit)\n",
    "    else:\n",
    "        n_ttest = ttest_crit\n",
    "    ttestX = trainX.iloc[:,np.argsort(pval)[:n_ttest]]\n",
    "    print('ttestX.shape:', ttestX.shape)\n",
    "    \n",
    "    ### step 3: automatic feature selection\n",
    "    # to be used for pandas dataframe\n",
    "    fs_res = [] \n",
    "    fs_labels = [(mlab, collab) for mlab in fs_model_names for collab in ['Xs', 'freqs']]\n",
    "    fs_labels = pd.MultiIndex.from_tuples(fs_labels)\n",
    "    # union set of frequent variable names\n",
    "    fs_union_xs = set() \n",
    "    if fs_method!=1:\n",
    "        fs_niter=trainX.shape[0]\n",
    "    fs_crit = fs_niter * 2/3\n",
    "    for fs_model, data_input in fs_models:\n",
    "        if data_input == 1:\n",
    "            data_input = trainX\n",
    "        elif data_input == 2:\n",
    "            data_input = ttestX\n",
    "        fs, xs = FE_cv(scaler, fs_model, data_input, trainy, 1+(fs_method==1), fs_niter)\n",
    "        fs_res.append(xs)\n",
    "        fs_res.append(fs)\n",
    "        fs_union_xs = fs_union_xs.union(set(np.array(xs)[(np.array(fs)>=fs_crit)]))\n",
    "    fs_res = np.array(fs_res).transpose()\n",
    "    fs_table = pd.DataFrame(fs_res, columns=fs_labels)\n",
    "    print('results from feature selection:')\n",
    "    print(fs_table) \n",
    "    \n",
    "    return fs_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(\n",
    "           path='AllNewFeatures1.csv', \n",
    "           eval_method=1,\n",
    "           eval_models=[SVC(kernel='linear'), SVC(kernel='rbf'),\n",
    "                        LogisticRegression(solver='liblinear'), \n",
    "                        KNeighborsClassifier(3, algorithm='auto'),\n",
    "                        KNeighborsClassifier(5, algorithm='auto'),\n",
    "                        DecisionTreeClassifier(max_depth=2, random_state=0),\n",
    "                        DecisionTreeClassifier(max_depth=3, random_state=0)],\n",
    "           eval_model_names=['SVM linear', 'SVM rbf', 'LR', 'KNN 3', 'KNN 5', 'DTree 2', 'DTree 3'],\n",
    "           customized_Xs=[],\n",
    "           scaler=StandardScaler(),\n",
    "           print_loo=False):\n",
    "    '''\n",
    "    path: data file name\n",
    "    ttest_crit: integer for top N variables; float for cutoff of p-value\n",
    "    eval_method: 1: LOO + 80/20 x 100; 2: LOO + 80/20 x 100 + 80/20 x 1\n",
    "    \n",
    "    the default values are the ones used in the final results\n",
    "    '''\n",
    "    # original data\n",
    "    allft = pd.read_csv(path)\n",
    "    ally = allft['Group']\n",
    "    allX = allft.iloc[:,2:]\n",
    "    \n",
    "    Xs = [] + \\\n",
    "         [allX[cols] for cols in customized_Xs]\n",
    "    if eval_method==1:\n",
    "        cv_res = cv(Xs, eval_models, scaler, ally, [], print_loo=print_loo)\n",
    "        method_labels = ['LOO', '80/20']\n",
    "    else:\n",
    "        trainX, testX, trainy, testy = train_test_split(allX, ally, test_size=7/37, random_state=5)\n",
    "        cv_res = cv(Xs, eval_models, scaler, ally, testy.index, print_loo=print_loo)\n",
    "        method_labels = ['LOO', '80/20', 'testset']\n",
    "    Xs_labels = [] + ['X'+str(i+1) for i in range(len(customized_Xs))]\n",
    "    for x, lab in zip(Xs, Xs_labels):\n",
    "        print(lab, '   ', list(x.columns))\n",
    "    \n",
    "    eval_labels = [(xlab, mlab) for xlab in Xs_labels for mlab in method_labels]\n",
    "    eval_labels = pd.MultiIndex.from_tuples(eval_labels)\n",
    "    eval_table = pd.DataFrame(cv_res, columns=eval_labels, index=eval_model_names)    \n",
    "    print('evaluation results:')\n",
    "    print(round(eval_table,3)*100)\n",
    "    return Xs, eval_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttestX.shape: (37, 31)\n",
      "results from feature selection:\n",
      "               SelectKBest                       RFE(SVM)        \\\n",
      "                        Xs freqs                       Xs freqs   \n",
      "0        Curvature_mean_PD    26        Curvature_mean_PD    23   \n",
      "1       CrossArea_mean_PD2    18  Curvature_integration_P    22   \n",
      "2  Curvature_integration_P    13                 LineDist    18   \n",
      "3        CrossArea_max_PD2    11        Diameter_normalD2    18   \n",
      "4         Curvature_mean_P     9      Eccentricity_std_P2    17   \n",
      "5         Ratio_Dpnordnor1     9                PointDist     6   \n",
      "6       MajorAxis_mean_PD2     8        MinorAxis_mean_D2     6   \n",
      "\n",
      "                   RFE(LR)                          RFE(RF)        \n",
      "                        Xs freqs                         Xs freqs  \n",
      "0        Curvature_mean_PD    28          Diameter_normalD2    25  \n",
      "1      Eccentricity_std_P2    22          Curvature_mean_PD    19  \n",
      "2  Curvature_integration_P    20        Eccentricity_std_P2    15  \n",
      "3                 LineDist    19  Eccentricity_variation_D2    12  \n",
      "4         Ratio_Dpnordnor1    17           Ratio_Dpnordnor1    10  \n",
      "5        Diameter_normalD2     8    Curvature_integration_P     9  \n",
      "6         Ratio_Dpnordnor2     7          MajorAxis_mean_D2     9  \n"
     ]
    }
   ],
   "source": [
    "fs_table = feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1     ['Curvature_mean_PD', 'Diameter_normalD2', 'Eccentricity_std_P2', 'Curvature_integration_P', 'CrossArea_mean_PD2']\n",
      "X2     ['Curvature_mean_PD', 'Diameter_normalD2', 'Eccentricity_std_P2', 'Curvature_integration_P']\n",
      "X3     ['Diameter_normalD2', 'Curvature_mean_PD', 'Eccentricity_std_P2']\n",
      "X4     ['Diameter_normalD2', 'Curvature_mean_PD']\n",
      "X5     ['Diameter_normalD2', 'Eccentricity_std_P2']\n",
      "X6     ['Curvature_mean_PD', 'Eccentricity_std_P2']\n",
      "evaluation results:\n",
      "              X1          X2          X3          X4          X5          X6  \\\n",
      "             LOO 80/20   LOO 80/20   LOO 80/20   LOO 80/20   LOO 80/20   LOO   \n",
      "SVM linear  94.6  89.4  86.5  88.0  86.5  83.6  83.8  81.8  78.4  72.2  81.1   \n",
      "SVM rbf     83.8  81.6  86.5  83.4  81.1  77.5  78.4  72.5  75.7  76.8  78.4   \n",
      "LR          94.6  91.5  86.5  87.0  86.5  82.6  83.8  81.8  78.4  75.6  78.4   \n",
      "KNN 3       83.8  83.5  83.8  78.1  75.7  72.4  73.0  74.5  64.9  68.6  67.6   \n",
      "KNN 5       86.5  83.0  83.8  82.1  75.7  75.8  75.7  77.4  73.0  73.9  75.7   \n",
      "DTree 2     83.8  78.6  83.8  78.0  83.8  78.4  73.0  76.0  83.8  79.2  75.7   \n",
      "DTree 3     89.2  82.1  89.2  82.2  81.1  78.1  75.7  77.9  75.7  77.0  62.2   \n",
      "\n",
      "                  \n",
      "           80/20  \n",
      "SVM linear  77.6  \n",
      "SVM rbf     72.9  \n",
      "LR          78.1  \n",
      "KNN 3       69.0  \n",
      "KNN 5       71.5  \n",
      "DTree 2     66.4  \n",
      "DTree 3     64.1  \n"
     ]
    }
   ],
   "source": [
    "Xs, cv_table = modelling(\n",
    "       customized_Xs=[['Curvature_mean_PD','Diameter_normalD2','Eccentricity_std_P2','Curvature_integration_P','CrossArea_mean_PD2'],\n",
    "                      ['Curvature_mean_PD','Diameter_normalD2','Eccentricity_std_P2','Curvature_integration_P'],\n",
    "                      ['Diameter_normalD2','Curvature_mean_PD','Eccentricity_std_P2'],\n",
    "                      ['Diameter_normalD2','Curvature_mean_PD'],\n",
    "                      ['Diameter_normalD2','Eccentricity_std_P2'],\n",
    "                      ['Curvature_mean_PD','Eccentricity_std_P2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">SelectKBest</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFE(SVM)</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFE(LR)</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFE(RF)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Xs</th>\n",
       "      <th>freqs</th>\n",
       "      <th>Xs</th>\n",
       "      <th>freqs</th>\n",
       "      <th>Xs</th>\n",
       "      <th>freqs</th>\n",
       "      <th>Xs</th>\n",
       "      <th>freqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Curvature_mean_PD</td>\n",
       "      <td>26</td>\n",
       "      <td>Curvature_mean_PD</td>\n",
       "      <td>23</td>\n",
       "      <td>Curvature_mean_PD</td>\n",
       "      <td>28</td>\n",
       "      <td>Diameter_normalD2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CrossArea_mean_PD2</td>\n",
       "      <td>18</td>\n",
       "      <td>Curvature_integration_P</td>\n",
       "      <td>22</td>\n",
       "      <td>Eccentricity_std_P2</td>\n",
       "      <td>22</td>\n",
       "      <td>Curvature_mean_PD</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Curvature_integration_P</td>\n",
       "      <td>13</td>\n",
       "      <td>LineDist</td>\n",
       "      <td>18</td>\n",
       "      <td>Curvature_integration_P</td>\n",
       "      <td>20</td>\n",
       "      <td>Eccentricity_std_P2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CrossArea_max_PD2</td>\n",
       "      <td>11</td>\n",
       "      <td>Diameter_normalD2</td>\n",
       "      <td>18</td>\n",
       "      <td>LineDist</td>\n",
       "      <td>19</td>\n",
       "      <td>Eccentricity_variation_D2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Curvature_mean_P</td>\n",
       "      <td>9</td>\n",
       "      <td>Eccentricity_std_P2</td>\n",
       "      <td>17</td>\n",
       "      <td>Ratio_Dpnordnor1</td>\n",
       "      <td>17</td>\n",
       "      <td>Ratio_Dpnordnor1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ratio_Dpnordnor1</td>\n",
       "      <td>9</td>\n",
       "      <td>PointDist</td>\n",
       "      <td>6</td>\n",
       "      <td>Diameter_normalD2</td>\n",
       "      <td>8</td>\n",
       "      <td>Curvature_integration_P</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MajorAxis_mean_PD2</td>\n",
       "      <td>8</td>\n",
       "      <td>MinorAxis_mean_D2</td>\n",
       "      <td>6</td>\n",
       "      <td>Ratio_Dpnordnor2</td>\n",
       "      <td>7</td>\n",
       "      <td>MajorAxis_mean_D2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SelectKBest                       RFE(SVM)        \\\n",
       "                        Xs freqs                       Xs freqs   \n",
       "0        Curvature_mean_PD    26        Curvature_mean_PD    23   \n",
       "1       CrossArea_mean_PD2    18  Curvature_integration_P    22   \n",
       "2  Curvature_integration_P    13                 LineDist    18   \n",
       "3        CrossArea_max_PD2    11        Diameter_normalD2    18   \n",
       "4         Curvature_mean_P     9      Eccentricity_std_P2    17   \n",
       "5         Ratio_Dpnordnor1     9                PointDist     6   \n",
       "6       MajorAxis_mean_PD2     8        MinorAxis_mean_D2     6   \n",
       "\n",
       "                   RFE(LR)                          RFE(RF)        \n",
       "                        Xs freqs                         Xs freqs  \n",
       "0        Curvature_mean_PD    28          Diameter_normalD2    25  \n",
       "1      Eccentricity_std_P2    22          Curvature_mean_PD    19  \n",
       "2  Curvature_integration_P    20        Eccentricity_std_P2    15  \n",
       "3                 LineDist    19  Eccentricity_variation_D2    12  \n",
       "4         Ratio_Dpnordnor1    17           Ratio_Dpnordnor1    10  \n",
       "5        Diameter_normalD2     8    Curvature_integration_P     9  \n",
       "6         Ratio_Dpnordnor2     7          MajorAxis_mean_D2     9  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtable = []\n",
    "names = []\n",
    "multidx = fs_table.columns\n",
    "for i in range(len(multidx)):\n",
    "    if i%2 == 1:\n",
    "        continue\n",
    "    idx1, idx2 = multidx[i]\n",
    "    names.append(idx1)\n",
    "    subtable.append(fs_table[idx1].set_index(idx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltable = subtable[0]\n",
    "for i in range(1, len(subtable)):\n",
    "    alltable = alltable.merge(subtable[i], 'outer', left_index=True, right_index=True, sort=False)\n",
    "alltable.columns = names\n",
    "alltable = alltable.fillna(0).astype(int)\n",
    "alltable = alltable.sort_values('SelectKBest', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SelectKBest</th>\n",
       "      <th>RFE(SVM)</th>\n",
       "      <th>RFE(LR)</th>\n",
       "      <th>RFE(RF)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diameter_normalD2</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eccentricity_std_P2</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eccentricity_variation_D2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LineDist</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MajorAxis_mean_D2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinorAxis_mean_D2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PointDist</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ratio_Dpnordnor2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MajorAxis_mean_PD2</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curvature_mean_P</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ratio_Dpnordnor1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrossArea_max_PD2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curvature_integration_P</th>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrossArea_mean_PD2</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curvature_mean_PD</th>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SelectKBest  RFE(SVM)  RFE(LR)  RFE(RF)\n",
       "Xs                                                                \n",
       "Diameter_normalD2                    0        18        8       25\n",
       "Eccentricity_std_P2                  0        17       22       15\n",
       "Eccentricity_variation_D2            0         0        0       12\n",
       "LineDist                             0        18       19        0\n",
       "MajorAxis_mean_D2                    0         0        0        9\n",
       "MinorAxis_mean_D2                    0         6        0        0\n",
       "PointDist                            0         6        0        0\n",
       "Ratio_Dpnordnor2                     0         0        7        0\n",
       "MajorAxis_mean_PD2                   8         0        0        0\n",
       "Curvature_mean_P                     9         0        0        0\n",
       "Ratio_Dpnordnor1                     9         0       17       10\n",
       "CrossArea_max_PD2                   11         0        0        0\n",
       "Curvature_integration_P             13        22       20        9\n",
       "CrossArea_mean_PD2                  18         0        0        0\n",
       "Curvature_mean_PD                   26        23       28       19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
